{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72586367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0v/7v6b_kx92wn32v08jvcl87_h0000gn/T/ipykernel_33114/973270851.py:5: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  supplemental_df = pd.read_csv('../data/supplementary_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "  ✓ Week 01 loaded\n",
      "  ✓ Week 02 loaded\n",
      "  ✓ Week 03 loaded\n",
      "  ✓ Week 04 loaded\n",
      "  ✓ Week 05 loaded\n",
      "  ✓ Week 06 loaded\n",
      "  ✓ Week 07 loaded\n",
      "  ✓ Week 08 loaded\n",
      "  ✓ Week 09 loaded\n",
      "  ✓ Week 10 loaded\n",
      "  ✓ Week 11 loaded\n",
      "  ✓ Week 12 loaded\n",
      "  ✓ Week 13 loaded\n",
      "  ✓ Week 14 loaded\n",
      "  ✓ Week 15 loaded\n",
      "  ✓ Week 16 loaded\n",
      "  ✓ Week 17 loaded\n",
      "  ✓ Week 18 loaded\n",
      "\n",
      "✓ Total input rows: 4,880,579\n",
      "✓ Total output rows: 562,936\n",
      "✓ Man coverage rows: 1,293,453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load supplementary data (same across all weeks)\n",
    "supplemental_df = pd.read_csv('../data/supplementary_data.csv')\n",
    "\n",
    "# Load all weeks\n",
    "all_input_dfs = []\n",
    "all_output_dfs = []\n",
    "\n",
    "weeks = range(1, 19)  # Weeks 1-18\n",
    "\n",
    "print(\"Loading data...\")\n",
    "for week in weeks:\n",
    "    try:\n",
    "        input_path = f'../data/train/input_2023_w{week:02d}.csv'\n",
    "        output_path = f'../data/train/output_2023_w{week:02d}.csv'\n",
    "        \n",
    "        input_df = pd.read_csv(input_path)\n",
    "        output_df = pd.read_csv(output_path)\n",
    "        \n",
    "        all_input_dfs.append(input_df)\n",
    "        all_output_dfs.append(output_df)\n",
    "        \n",
    "        print(f\"  ✓ Week {week:02d} loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ✗ Week {week:02d} not found\")\n",
    "\n",
    "# Combine all weeks\n",
    "input_df = pd.concat(all_input_dfs, ignore_index=True)\n",
    "output_df = pd.concat(all_output_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Total input rows: {len(input_df):,}\")\n",
    "print(f\"✓ Total output rows: {len(output_df):,}\")\n",
    "\n",
    "# Merge and filter to man coverage\n",
    "df = pd.merge(input_df, supplemental_df, on=['game_id','play_id'], how='left')\n",
    "df_man = df[~df['team_coverage_type'].str.contains(\"ZONE\", na=False)]\n",
    "\n",
    "print(f\"✓ Man coverage rows: {len(df_man):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62850b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nfl_id        player_name player_position         player_role\n",
      "15964   54527         Bryan Cook              FS  Defensive Coverage\n",
      "15984   54600    Joshua Williams              CB  Defensive Coverage\n",
      "16004   46137        Justin Reid              SS  Defensive Coverage\n",
      "16024   53487        Nick Bolton             MLB  Defensive Coverage\n",
      "16044   54486     Trent McDuffie              CB  Defensive Coverage\n",
      "16064   52471     Willie Gay Jr.             ILB  Defensive Coverage\n",
      "16084   47856   David Montgomery              RB  Other Route Runner\n",
      "16104   43584      Kalif Raymond              WR  Other Route Runner\n",
      "16124   38696       Marvin Jones              WR  Other Route Runner\n",
      "16144   55899        Sam LaPorta              TE  Other Route Runner\n",
      "16164   43290         Jared Goff              QB              Passer\n",
      "16184   53541  Amon-Ra St. Brown              WR   Targeted Receiver\n"
     ]
    }
   ],
   "source": [
    "test_play = df_man[df_man['pass_result'] == 'IN'].iloc[0]\n",
    "test_game_id = 2023090700\n",
    "test_play_id = 3032\n",
    "\n",
    "# Filter output data to just this one play\n",
    "output_test = output_df[\n",
    "    (output_df['game_id'] == test_game_id) & \n",
    "    (output_df['play_id'] == test_play_id)\n",
    "]\n",
    "\n",
    "# From input_df, who are the players on this play?\n",
    "input_test = input_df[\n",
    "    (input_df['game_id'] == test_game_id) & \n",
    "    (input_df['play_id'] == test_play_id)\n",
    "]\n",
    "\n",
    "# Look at player roles\n",
    "print(input_test[['nfl_id', 'player_name', 'player_position', 'player_role']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e877a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeted: Amon-Ra St. Brown (ID: 53541)\n",
      "\n",
      "CBs in output: 1\n",
      "  Justin Reid (SS):\n",
      "    First frame: 2.51 yards\n",
      "    Average: 1.30 yards\n",
      "    Final frame: 0.51 yards\n",
      "\n",
      "✓ Primary defender: Justin Reid (ID: 46137)\n",
      "✓ Average distance: 1.30 yards\n",
      "\n",
      "--- METRICS ---\n",
      "Frames: 9\n",
      "Depth ratio: 9.09\n",
      "Separation start: 2.51 yards\n",
      "Separation end: 0.51 yards\n",
      "Separation change: -2.00 yards\n",
      "\n",
      "✓ Classification: CONSERVATIVE (tight coverage)\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "BOUNDARY_THRESHOLD = 12\n",
    "\n",
    "# Get targeted receiver\n",
    "targeted_wr = input_test[input_test['player_role'] == 'Targeted Receiver']\n",
    "if len(targeted_wr) == 0:\n",
    "    print(\"No targeted receiver - skipping\")\n",
    "else:\n",
    "    wr_id = targeted_wr['nfl_id'].iloc[0]\n",
    "    wr_name = targeted_wr['player_name'].iloc[0]\n",
    "    \n",
    "    print(f\"Targeted: {wr_name} (ID: {wr_id})\")\n",
    "    \n",
    "    # Get all CBs/DBs in coverage\n",
    "    cb_ids = input_test[\n",
    "        (input_test['player_role'] == 'Defensive Coverage') & \n",
    "        (input_test['player_position'].isin(['CB', 'DB', 'SS', 'FS']))\n",
    "    ]['nfl_id'].unique()\n",
    "    \n",
    "    # Filter to CBs that have output data\n",
    "    cbs_in_output = []\n",
    "    for cb_id in cb_ids:\n",
    "        if len(output_test[output_test['nfl_id'] == cb_id]) > 0:\n",
    "            cbs_in_output.append(cb_id)\n",
    "    \n",
    "    if len(cbs_in_output) == 0:\n",
    "        print(\"No CBs in output - skipping\")\n",
    "    else:\n",
    "        print(f\"\\nCBs in output: {len(cbs_in_output)}\")\n",
    "        \n",
    "        # Calculate AVERAGE distance for each CB across all frames\n",
    "        cb_avg_distances = {}\n",
    "        \n",
    "        for cb_id in cbs_in_output:\n",
    "            # Get CB and WR frames\n",
    "            cb_frames = output_test[output_test['nfl_id'] == cb_id][['frame_id', 'x', 'y']]\n",
    "            wr_frames = output_test[output_test['nfl_id'] == wr_id][['frame_id', 'x', 'y']]\n",
    "            \n",
    "            # Merge on frame_id to align them\n",
    "            merged = pd.merge(\n",
    "                cb_frames,\n",
    "                wr_frames,\n",
    "                on='frame_id',\n",
    "                suffixes=('_cb', '_wr')\n",
    "            )\n",
    "            \n",
    "            if len(merged) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate distance at each frame\n",
    "            merged['distance'] = np.sqrt(\n",
    "                (merged['x_cb'] - merged['x_wr'])**2 + \n",
    "                (merged['y_cb'] - merged['y_wr'])**2\n",
    "            )\n",
    "            \n",
    "            # OPTION A: Simple average\n",
    "            avg_distance = merged['distance'].mean()\n",
    "            \n",
    "            # OPTION B: Weighted average (later frames matter more)\n",
    "            # Uncomment to use weighted:\n",
    "            # weights = np.linspace(1, 2, len(merged))\n",
    "            # avg_distance = np.average(merged['distance'], weights=weights)\n",
    "            \n",
    "            cb_avg_distances[cb_id] = avg_distance\n",
    "            \n",
    "            # Print info\n",
    "            cb_name = input_test[input_test['nfl_id'] == cb_id]['player_name'].iloc[0]\n",
    "            cb_pos = input_test[input_test['nfl_id'] == cb_id]['player_position'].iloc[0]\n",
    "            print(f\"  {cb_name} ({cb_pos}):\")\n",
    "            print(f\"    First frame: {merged['distance'].iloc[0]:.2f} yards\")\n",
    "            print(f\"    Average: {avg_distance:.2f} yards\")\n",
    "            print(f\"    Final frame: {merged['distance'].iloc[-1]:.2f} yards\")\n",
    "        \n",
    "        if len(cb_avg_distances) == 0:\n",
    "            print(\"No valid CB-WR matchups - skipping\")\n",
    "        else:\n",
    "            # Pick CB with LOWEST average distance\n",
    "            primary_cb_id = min(cb_avg_distances, key=cb_avg_distances.get)\n",
    "            primary_cb_name = input_test[input_test['nfl_id'] == primary_cb_id]['player_name'].iloc[0]\n",
    "            \n",
    "            print(f\"\\n✓ Primary defender: {primary_cb_name} (ID: {primary_cb_id})\")\n",
    "            print(f\"✓ Average distance: {cb_avg_distances[primary_cb_id]:.2f} yards\")\n",
    "            \n",
    "            # NOW calculate your metrics using this CB\n",
    "            cb_frames = output_test[output_test['nfl_id'] == primary_cb_id].sort_values('frame_id')\n",
    "            wr_frames = output_test[output_test['nfl_id'] == wr_id].sort_values('frame_id')\n",
    "            \n",
    "            cb_start = cb_frames.iloc[0]\n",
    "            cb_end = cb_frames.iloc[-1]\n",
    "            wr_start = wr_frames.iloc[0]\n",
    "            wr_end = wr_frames.iloc[-1]\n",
    "            \n",
    "            # Depth change\n",
    "            cb_depth_change = abs(cb_end['x'] - cb_start['x'])\n",
    "            wr_depth_change = abs(wr_end['x'] - wr_start['x'])\n",
    "            depth_ratio = cb_depth_change / wr_depth_change if wr_depth_change > 0 else 0\n",
    "            \n",
    "            # Separation\n",
    "            separation_start = np.sqrt(\n",
    "                (cb_start['x'] - wr_start['x'])**2 + \n",
    "                (cb_start['y'] - wr_start['y'])**2\n",
    "            )\n",
    "            separation_end = np.sqrt(\n",
    "                (cb_end['x'] - wr_end['x'])**2 + \n",
    "                (cb_end['y'] - wr_end['y'])**2\n",
    "            )\n",
    "            separation_change = separation_end - separation_start\n",
    "            \n",
    "            print(f\"\\n--- METRICS ---\")\n",
    "            print(f\"Frames: {len(cb_frames)}\")\n",
    "            print(f\"Depth ratio: {depth_ratio:.2f}\")\n",
    "            print(f\"Separation start: {separation_start:.2f} yards\")\n",
    "            print(f\"Separation end: {separation_end:.2f} yards\")\n",
    "            print(f\"Separation change: {separation_change:+.2f} yards\")\n",
    "            \n",
    "            # Classification\n",
    "            if separation_end < 3:\n",
    "                if depth_ratio < 0.9:\n",
    "                    classification = \"AGGRESSIVE (successful undercut)\"\n",
    "                else:\n",
    "                    classification = \"CONSERVATIVE (tight coverage)\"\n",
    "            elif separation_change < -2:\n",
    "                if depth_ratio < 0.9 and separation_end < 6:\n",
    "                    classification = \"AGGRESSIVE (closing on route)\"\n",
    "                else:\n",
    "                    classification = \"BEATEN (trailing but closing)\"\n",
    "            else:\n",
    "                if separation_end > 5:\n",
    "                    classification = \"BEATEN (lost coverage)\"\n",
    "                else:\n",
    "                    classification = \"CONSERVATIVE (maintaining distance)\"\n",
    "            \n",
    "            print(f\"\\n✓ Classification: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29049973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Valid play: game=2023090700, play=194\n",
      "  Result: C\n"
     ]
    }
   ],
   "source": [
    "# Simpler approach - any CB on any receiver\n",
    "for idx in range(min(20, len(df_man))):\n",
    "    test_play = df_man.iloc[idx]\n",
    "    test_game_id = test_play['game_id']\n",
    "    test_play_id = test_play['play_id']\n",
    "    \n",
    "    input_test = input_df[\n",
    "        (input_df['game_id'] == test_game_id) & \n",
    "        (input_df['play_id'] == test_play_id)\n",
    "    ]\n",
    "    \n",
    "    output_test = output_df[\n",
    "        (output_df['game_id'] == test_game_id) & \n",
    "        (output_df['play_id'] == test_play_id)\n",
    "    ]\n",
    "    \n",
    "    # Get targeted receiver\n",
    "    targeted_wr = input_test[input_test['player_role'] == 'Targeted Receiver']\n",
    "    if len(targeted_wr) == 0:\n",
    "        continue\n",
    "    \n",
    "    wr_id = targeted_wr['nfl_id'].iloc[0]\n",
    "    \n",
    "    # Check if WR in output\n",
    "    if len(output_test[output_test['nfl_id'] == wr_id]) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get CBs\n",
    "    cb_ids = input_test[\n",
    "        (input_test['player_role'] == 'Defensive Coverage') & \n",
    "        (input_test['player_position'].isin(['CB', 'DB', 'SS', 'FS']))  # Include safeties too\n",
    "    ]['nfl_id'].unique()\n",
    "    \n",
    "    # Check if any CB in output\n",
    "    cbs_in_output = []\n",
    "    for cb_id in cb_ids:\n",
    "        if len(output_test[output_test['nfl_id'] == cb_id]) > 0:\n",
    "            cbs_in_output.append(cb_id)\n",
    "    \n",
    "    if len(cbs_in_output) > 0:\n",
    "        print(f\"✓ Valid play: game={test_game_id}, play={test_play_id}\")\n",
    "        print(f\"  Result: {test_play['pass_result']}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f48ea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing 4055 unique plays across all 18 weeks...\n",
      "Processing play 0/4055...\n",
      "Processing play 500/4055...\n",
      "Processing play 1000/4055...\n",
      "Processing play 1500/4055...\n",
      "Processing play 2000/4055...\n",
      "Processing play 2500/4055...\n",
      "Processing play 3000/4055...\n",
      "Processing play 3500/4055...\n",
      "Processing play 4000/4055...\n",
      "\n",
      "✓ Analysis complete!\n",
      "  Analyzed: 3742 plays\n",
      "  Skipped: 313 plays\n",
      "\n",
      "============================================================\n",
      "ANALYSIS ACROSS ALL 18 WEEKS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "HIGH-LEVEL DECISION DISTRIBUTION\n",
      "============================================================\n",
      "decision_type\n",
      "CONSERVATIVE    3295\n",
      "AGGRESSIVE       447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "decision_type\n",
      "CONSERVATIVE    88.1\n",
      "AGGRESSIVE      11.9\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "DETAILED CLASSIFICATION DISTRIBUTION\n",
      "============================================================\n",
      "classification\n",
      "CONS: Press (Complete)           959\n",
      "CONS: Press (INC)                848\n",
      "CONS: Trail Coverage             471\n",
      "CONS: Reactive Close             269\n",
      "CONS: Reactive Mirror            242\n",
      "CONS: Broke With WR              205\n",
      "BEATEN                           159\n",
      "AGG: Successful Jump (INC)       151\n",
      "AGG: Undercut Fail (Complete)    151\n",
      "CONS: Standard                   100\n",
      "AGG: Overcommit (Beaten)          78\n",
      "AGG: Hard Break (Complete)        59\n",
      "CONS: Press (INT)                 42\n",
      "AGG: Successful Jump (INT)         8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "AGGRESSIVE: Success Rate\n",
      "============================================================\n",
      "Total aggressive decisions: 447\n",
      "\n",
      "Breakdown:\n",
      "classification\n",
      "AGG: Successful Jump (INC)       151\n",
      "AGG: Undercut Fail (Complete)    151\n",
      "AGG: Overcommit (Beaten)          78\n",
      "AGG: Hard Break (Complete)        59\n",
      "AGG: Successful Jump (INT)         8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcomes:\n",
      "pass_result\n",
      "C     288\n",
      "I     151\n",
      "IN      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Success rate (INT or INC): 35.6%\n",
      "Interception rate: 1.8%\n",
      "\n",
      "============================================================\n",
      "CONSERVATIVE: Breakdown by Style\n",
      "============================================================\n",
      "Total conservative decisions: 3295\n",
      "\n",
      "Top classifications:\n",
      "classification\n",
      "CONS: Press (Complete)    959\n",
      "CONS: Press (INC)         848\n",
      "CONS: Trail Coverage      471\n",
      "CONS: Reactive Close      269\n",
      "CONS: Reactive Mirror     242\n",
      "CONS: Broke With WR       205\n",
      "BEATEN                    159\n",
      "CONS: Standard            100\n",
      "CONS: Press (INT)          42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Press Coverage outcomes:\n",
      "pass_result\n",
      "C     959\n",
      "I     848\n",
      "IN     42\n",
      "Name: count, dtype: int64\n",
      "Completion rate: 51.9%\n",
      "Interception rate: 2.3%\n",
      "\n",
      "============================================================\n",
      "PASS RESULT BY DECISION TYPE\n",
      "============================================================\n",
      "pass_result       C     I   IN\n",
      "decision_type                 \n",
      "AGGRESSIVE     64.4  33.8  1.8\n",
      "CONSERVATIVE   57.8  40.1  2.1\n",
      "\n",
      "============================================================\n",
      "COMPARISON: Week 1 vs All Weeks\n",
      "============================================================\n",
      "Week 1 sample: 211 plays\n",
      "All weeks sample: 3742 plays\n",
      "\n",
      "Week 1 aggressive rate: 13.3%\n",
      "All weeks aggressive rate: 11.9%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "skipped = 0\n",
    "\n",
    "print(f\"\\nAnalyzing {len(unique_plays)} unique plays across all 18 weeks...\")\n",
    "\n",
    "for idx in range(len(unique_plays)):\n",
    "    test_play = unique_plays.iloc[idx]\n",
    "    test_game_id = test_play['game_id']\n",
    "    test_play_id = test_play['play_id']\n",
    "    los_x = test_play['absolute_yardline_number']\n",
    "    \n",
    "    if idx % 500 == 0:  # Progress every 500 plays instead of 50\n",
    "        print(f\"Processing play {idx}/{len(unique_plays)}...\")\n",
    "    \n",
    "    # [Rest of your classification loop - exact same code]\n",
    "    # Load play data\n",
    "    input_test = input_df[\n",
    "        (input_df['game_id'] == test_game_id) & \n",
    "        (input_df['play_id'] == test_play_id)\n",
    "    ]\n",
    "    \n",
    "    output_test = output_df[\n",
    "        (output_df['game_id'] == test_game_id) & \n",
    "        (output_df['play_id'] == test_play_id)\n",
    "    ]\n",
    "    \n",
    "    # Get targeted receiver\n",
    "    targeted_wr = input_test[input_test['player_role'] == 'Targeted Receiver']\n",
    "    if len(targeted_wr) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    wr_id = targeted_wr['nfl_id'].iloc[0]\n",
    "    wr_name = targeted_wr['player_name'].iloc[0]\n",
    "    \n",
    "    if len(output_test[output_test['nfl_id'] == wr_id]) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Get CBs in coverage\n",
    "    cb_ids = input_test[\n",
    "        (input_test['player_role'] == 'Defensive Coverage') & \n",
    "        (input_test['player_position'].isin(['CB', 'DB', 'SS', 'FS']))\n",
    "    ]['nfl_id'].unique()\n",
    "    \n",
    "    cbs_in_output = []\n",
    "    for cb_id in cb_ids:\n",
    "        if len(output_test[output_test['nfl_id'] == cb_id]) > 0:\n",
    "            cbs_in_output.append(cb_id)\n",
    "    \n",
    "    if len(cbs_in_output) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Find primary coverage\n",
    "    cb_avg_distances = {}\n",
    "    \n",
    "    for cb_id in cbs_in_output:\n",
    "        cb_frames = output_test[output_test['nfl_id'] == cb_id][['frame_id', 'x', 'y']]\n",
    "        wr_frames = output_test[output_test['nfl_id'] == wr_id][['frame_id', 'x', 'y']]\n",
    "        \n",
    "        merged = pd.merge(cb_frames, wr_frames, on='frame_id', suffixes=('_cb', '_wr'))\n",
    "        \n",
    "        if len(merged) == 0:\n",
    "            continue\n",
    "        \n",
    "        merged['distance'] = np.sqrt(\n",
    "            (merged['x_cb'] - merged['x_wr'])**2 + \n",
    "            (merged['y_cb'] - merged['y_wr'])**2\n",
    "        )\n",
    "        \n",
    "        avg_distance = merged['distance'].mean()\n",
    "        cb_avg_distances[cb_id] = avg_distance\n",
    "    \n",
    "    if len(cb_avg_distances) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    primary_cb_id = min(cb_avg_distances, key=cb_avg_distances.get)\n",
    "    primary_cb_info = input_test[input_test['nfl_id'] == primary_cb_id].iloc[0]\n",
    "    \n",
    "    # Get frame-by-frame data\n",
    "    cb_frames = output_test[output_test['nfl_id'] == primary_cb_id].sort_values('frame_id').reset_index(drop=True)\n",
    "    wr_frames = output_test[output_test['nfl_id'] == wr_id].sort_values('frame_id').reset_index(drop=True)\n",
    "    \n",
    "    if len(cb_frames) < 5 or len(wr_frames) < 5:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    num_frames = len(cb_frames)\n",
    "    early_end = num_frames // 3\n",
    "    late_start = 2 * num_frames // 3\n",
    "    \n",
    "    cb_early = cb_frames.iloc[:early_end]\n",
    "    cb_late = cb_frames.iloc[late_start:]\n",
    "    \n",
    "    early_dx = cb_early.iloc[-1]['x'] - cb_early.iloc[0]['x']\n",
    "    early_dy = cb_early.iloc[-1]['y'] - cb_early.iloc[0]['y']\n",
    "    early_direction = np.arctan2(early_dy, early_dx)\n",
    "    \n",
    "    late_dx = cb_late.iloc[-1]['x'] - cb_late.iloc[0]['x']\n",
    "    late_dy = cb_late.iloc[-1]['y'] - cb_late.iloc[0]['y']\n",
    "    late_direction = np.arctan2(late_dy, late_dx)\n",
    "    \n",
    "    direction_change = abs(late_direction - early_direction)\n",
    "    if direction_change > np.pi:\n",
    "        direction_change = 2 * np.pi - direction_change\n",
    "    direction_change_degrees = np.degrees(direction_change)\n",
    "    \n",
    "    cb_start = cb_frames.iloc[0]\n",
    "    cb_end = cb_frames.iloc[-1]\n",
    "    wr_start = wr_frames.iloc[0]\n",
    "    wr_end = wr_frames.iloc[-1]\n",
    "    \n",
    "    separation_start = np.sqrt(\n",
    "        (cb_start['x'] - wr_start['x'])**2 + \n",
    "        (cb_start['y'] - wr_start['y'])**2\n",
    "    )\n",
    "    separation_end = np.sqrt(\n",
    "        (cb_end['x'] - wr_end['x'])**2 + \n",
    "        (cb_end['y'] - wr_end['y'])**2\n",
    "    )\n",
    "    separation_change = separation_end - separation_start\n",
    "    \n",
    "    cb_los_start = abs(cb_start['x'] - los_x)\n",
    "    cb_los_end = abs(cb_end['x'] - los_x)\n",
    "    wr_los_start = abs(wr_start['x'] - los_x)\n",
    "    wr_los_end = abs(wr_end['x'] - los_x)\n",
    "    \n",
    "    cb_los_change = cb_los_end - cb_los_start\n",
    "    wr_los_change = wr_los_end - wr_los_start\n",
    "    los_change_diff = cb_los_change - wr_los_change\n",
    "    \n",
    "    pass_result = test_play['pass_result']\n",
    "    \n",
    "    # Classification\n",
    "    made_big_break = direction_change_degrees > 30\n",
    "    separated_from_wr = separation_change > 0.5\n",
    "    undercut_route = los_change_diff < -2.5 and separation_end > 4\n",
    "    \n",
    "    is_aggressive = (made_big_break and separated_from_wr) or undercut_route\n",
    "    \n",
    "    if is_aggressive:\n",
    "        if pass_result in ['IN', 'I']:\n",
    "            if pass_result == 'IN':\n",
    "                classification = \"AGG: Successful Jump (INT)\"\n",
    "            else:\n",
    "                classification = \"AGG: Successful Jump (INC)\"\n",
    "        else:\n",
    "            if separation_end > 8:\n",
    "                classification = \"AGG: Overcommit (Beaten)\"\n",
    "            elif direction_change_degrees > 60:\n",
    "                classification = \"AGG: Hard Break (Complete)\"\n",
    "            else:\n",
    "                classification = \"AGG: Undercut Fail (Complete)\"\n",
    "    else:\n",
    "        if separation_end > 8:\n",
    "            classification = \"BEATEN\"\n",
    "        elif separation_end < 3 and direction_change_degrees < 25:\n",
    "            if pass_result == 'C':\n",
    "                classification = \"CONS: Press (Complete)\"\n",
    "            elif pass_result == 'IN':\n",
    "                classification = \"CONS: Press (INT)\"\n",
    "            else:\n",
    "                classification = \"CONS: Press (INC)\"\n",
    "        elif 25 <= direction_change_degrees <= 50 and separation_end < 5:\n",
    "            if separation_change < -0.5:\n",
    "                classification = \"CONS: Reactive Close\"\n",
    "            else:\n",
    "                classification = \"CONS: Reactive Mirror\"\n",
    "        elif 3 <= separation_end <= 7:\n",
    "            classification = \"CONS: Trail Coverage\"\n",
    "        elif direction_change_degrees > 50 and separation_change < 0:\n",
    "            classification = \"CONS: Broke With WR\"\n",
    "        else:\n",
    "            classification = \"CONS: Standard\"\n",
    "    \n",
    "    results.append({\n",
    "        'game_id': test_game_id,\n",
    "        'play_id': test_play_id,\n",
    "        'pass_result': pass_result,\n",
    "        'wr_id': wr_id,\n",
    "        'wr_name': wr_name,\n",
    "        'cb_id': primary_cb_id,\n",
    "        'cb_name': primary_cb_info['player_name'],\n",
    "        'cb_position': primary_cb_info['player_position'],\n",
    "        'avg_distance': cb_avg_distances[primary_cb_id],\n",
    "        'direction_change_degrees': direction_change_degrees,\n",
    "        'separation_start': separation_start,\n",
    "        'separation_end': separation_end,\n",
    "        'separation_change': separation_change,\n",
    "        'los_change_diff': los_change_diff,\n",
    "        'classification': classification,\n",
    "        'decision_type': 'AGGRESSIVE' if is_aggressive else 'CONSERVATIVE',\n",
    "        'num_frames': num_frames\n",
    "    })\n",
    "\n",
    "print(f\"\\n✓ Analysis complete!\")\n",
    "print(f\"  Analyzed: {len(results)} plays\")\n",
    "print(f\"  Skipped: {skipped} plays\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# === SAME ANALYSIS AS BEFORE ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS ACROSS ALL 18 WEEKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HIGH-LEVEL DECISION DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(results_df['decision_type'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print((results_df['decision_type'].value_counts(normalize=True) * 100).round(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED CLASSIFICATION DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(results_df['classification'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AGGRESSIVE: Success Rate\")\n",
    "print(\"=\"*60)\n",
    "aggressive = results_df[results_df['decision_type'] == 'AGGRESSIVE']\n",
    "if len(aggressive) > 0:\n",
    "    print(f\"Total aggressive decisions: {len(aggressive)}\")\n",
    "    print(\"\\nBreakdown:\")\n",
    "    print(aggressive['classification'].value_counts())\n",
    "    print(f\"\\nOutcomes:\")\n",
    "    print(aggressive['pass_result'].value_counts())\n",
    "    \n",
    "    success_rate = len(aggressive[aggressive['pass_result'].isin(['I', 'IN'])]) / len(aggressive) * 100\n",
    "    int_rate = len(aggressive[aggressive['pass_result'] == 'IN']) / len(aggressive) * 100\n",
    "    print(f\"\\nSuccess rate (INT or INC): {success_rate:.1f}%\")\n",
    "    print(f\"Interception rate: {int_rate:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSERVATIVE: Breakdown by Style\")\n",
    "print(\"=\"*60)\n",
    "conservative = results_df[results_df['decision_type'] == 'CONSERVATIVE']\n",
    "if len(conservative) > 0:\n",
    "    print(f\"Total conservative decisions: {len(conservative)}\")\n",
    "    print(\"\\nTop classifications:\")\n",
    "    print(conservative['classification'].value_counts().head(10))\n",
    "    \n",
    "    print(\"\\nPress Coverage outcomes:\")\n",
    "    press = conservative[conservative['classification'].str.contains('Press')]\n",
    "    if len(press) > 0:\n",
    "        print(press['pass_result'].value_counts())\n",
    "        comp_rate = len(press[press['pass_result'] == 'C']) / len(press) * 100\n",
    "        int_rate = len(press[press['pass_result'] == 'IN']) / len(press) * 100\n",
    "        print(f\"Completion rate: {comp_rate:.1f}%\")\n",
    "        print(f\"Interception rate: {int_rate:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASS RESULT BY DECISION TYPE\")\n",
    "print(\"=\"*60)\n",
    "crosstab = pd.crosstab(results_df['decision_type'], results_df['pass_result'], normalize='index')\n",
    "print((crosstab * 100).round(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Week 1 vs All Weeks\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Week 1 sample: 211 plays\")\n",
    "print(f\"All weeks sample: {len(results_df)} plays\")\n",
    "print(f\"\\nWeek 1 aggressive rate: 13.3%\")\n",
    "print(f\"All weeks aggressive rate: {(len(aggressive) / len(results_df) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "766aac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHEN DOES AGGRESSIVE SUCCEED?\n",
      "\n",
      "By route type:\n",
      "pass_result                    C     I   IN\n",
      "route_of_targeted_receiver                 \n",
      "ANGLE                       50.0  50.0  0.0\n",
      "CORNER                      51.2  43.9  4.9\n",
      "CROSS                       68.6  31.4  0.0\n",
      "FLAT                        80.9  19.1  0.0\n",
      "GO                          52.8  47.2  0.0\n",
      "HITCH                       66.0  30.2  3.8\n",
      "IN                          53.3  43.3  3.3\n",
      "OUT                         72.9  26.0  1.0\n",
      "POST                        78.1  21.9  0.0\n",
      "SCREEN                      66.7  33.3  0.0\n",
      "SLANT                       52.2  39.1  8.7\n",
      "WHEEL                       45.5  54.5  0.0\n",
      "\n",
      "By down:\n",
      "pass_result     C     I   IN\n",
      "down                        \n",
      "1            65.2  33.9  0.9\n",
      "2            65.4  32.3  2.3\n",
      "3            63.6  34.8  1.6\n",
      "4            61.1  33.3  5.6\n",
      "\n",
      "By distance (3rd downs only):\n",
      "yards_to_go  pass_result\n",
      "1            C              0.636364\n",
      "             I              0.363636\n",
      "2            C              0.764706\n",
      "             I              0.235294\n",
      "3            C              0.730769\n",
      "             I              0.230769\n",
      "             IN             0.038462\n",
      "4            C              0.588235\n",
      "             I              0.411765\n",
      "5            I              0.625000\n",
      "             C              0.312500\n",
      "             IN             0.062500\n",
      "6            C              0.625000\n",
      "             I              0.333333\n",
      "             IN             0.041667\n",
      "7            C              0.571429\n",
      "             I              0.428571\n",
      "8            C              0.703704\n",
      "             I              0.296296\n",
      "9            I              0.600000\n",
      "             C              0.400000\n",
      "10           C              0.714286\n",
      "             I              0.285714\n",
      "11           C              0.800000\n",
      "             I              0.200000\n",
      "12           I              0.500000\n",
      "             C              0.500000\n",
      "14           C              1.000000\n",
      "15           C              1.000000\n",
      "16           I              1.000000\n",
      "17           I              0.500000\n",
      "             C              0.500000\n",
      "19           C              1.000000\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add contextual variables\n",
    "results_with_context = pd.merge(\n",
    "    results_df,\n",
    "    supplemental_df[[\n",
    "        'game_id', 'play_id',\n",
    "        'route_of_targeted_receiver',\n",
    "        'down', 'yards_to_go',\n",
    "        'yardline_number', 'quarter',\n",
    "        'pre_snap_home_score', 'pre_snap_visitor_score'\n",
    "    ]],\n",
    "    on=['game_id', 'play_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate score differential\n",
    "results_with_context['score_diff'] = (\n",
    "    results_with_context['pre_snap_home_score'] - \n",
    "    results_with_context['pre_snap_visitor_score']\n",
    ")\n",
    "\n",
    "# Analyze: When does aggressive work?\n",
    "aggressive_context = results_with_context[\n",
    "    results_with_context['decision_type'] == 'AGGRESSIVE'\n",
    "]\n",
    "\n",
    "print(\"WHEN DOES AGGRESSIVE SUCCEED?\")\n",
    "print(\"\\nBy route type:\")\n",
    "route_analysis = pd.crosstab(\n",
    "    aggressive_context['route_of_targeted_receiver'],\n",
    "    aggressive_context['pass_result'],\n",
    "    normalize='index'\n",
    ")\n",
    "print((route_analysis * 100).round(1))\n",
    "\n",
    "print(\"\\nBy down:\")\n",
    "down_analysis = pd.crosstab(\n",
    "    aggressive_context['down'],\n",
    "    aggressive_context['pass_result'],\n",
    "    normalize='index'\n",
    ")\n",
    "print((down_analysis * 100).round(1))\n",
    "\n",
    "print(\"\\nBy distance (3rd downs only):\")\n",
    "third_down_agg = aggressive_context[aggressive_context['down'] == 3]\n",
    "print(third_down_agg.groupby('yards_to_go')['pass_result'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab4033b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total INTs: 78\n",
      "\n",
      "INT classification breakdown:\n",
      "classification\n",
      "CONS: Press (INT)             42\n",
      "CONS: Reactive Close          12\n",
      "AGG: Successful Jump (INT)     8\n",
      "CONS: Trail Coverage           6\n",
      "CONS: Broke With WR            5\n",
      "CONS: Reactive Mirror          2\n",
      "BEATEN                         2\n",
      "CONS: Standard                 1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "What % of INTs are classified as aggressive?\n",
      "Aggressive INTs: 8 (10.3%)\n",
      "\n",
      "Average metrics for INT plays:\n",
      "               direction_change_degrees  separation_change  los_change_diff\n",
      "decision_type                                                              \n",
      "AGGRESSIVE                    50.000851           1.985388        -0.851250\n",
      "CONSERVATIVE                  24.210624          -0.555119        -0.820857\n"
     ]
    }
   ],
   "source": [
    "# Look at ALL interceptions\n",
    "all_ints = results_df[results_df['pass_result'] == 'IN']\n",
    "\n",
    "print(f\"Total INTs: {len(all_ints)}\")\n",
    "print(\"\\nINT classification breakdown:\")\n",
    "print(all_ints['classification'].value_counts())\n",
    "print(f\"\\nWhat % of INTs are classified as aggressive?\")\n",
    "print(f\"Aggressive INTs: {len(all_ints[all_ints['decision_type'] == 'AGGRESSIVE'])} ({len(all_ints[all_ints['decision_type'] == 'AGGRESSIVE'])/len(all_ints)*100:.1f}%)\")\n",
    "\n",
    "# Check metrics for INT plays\n",
    "print(\"\\nAverage metrics for INT plays:\")\n",
    "print(all_ints.groupby('decision_type')[[\n",
    "    'direction_change_degrees', \n",
    "    'separation_change', \n",
    "    'los_change_diff'\n",
    "]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29af56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most aggressive CBs (players with 20+ plays):\n",
      "                     aggression_rate  total_plays\n",
      "cb_name                                          \n",
      "Darious Williams            0.320000           25\n",
      "Patrick Peterson            0.280000           25\n",
      "Sauce Gardner               0.250000           28\n",
      "Sean Murphy-Bunting         0.225806           31\n",
      "A.J. Terrell                0.222222           36\n",
      "Carlton Davis III           0.206897           29\n",
      "L'Jarius Sneed              0.200000           30\n",
      "Jerry Jacobs                0.190476           21\n",
      "Martin Emerson              0.189189           37\n",
      "Darius Slay                 0.166667           36\n",
      "\n",
      "Most conservative CBs:\n",
      "                   aggression_rate  total_plays\n",
      "cb_name                                        \n",
      "Ja'Quan McMillian         0.045455           22\n",
      "Greg Newsome II           0.041667           24\n",
      "Jonathan Jones            0.035714           28\n",
      "Michael Davis             0.030303           33\n",
      "Asante Samuel             0.000000           22\n",
      "Michael Carter II         0.000000           26\n",
      "Kevin Byard               0.000000           21\n",
      "Chidobe Awuzie            0.000000           28\n",
      "Emmanuel Forbes           0.000000           29\n",
      "Cordale Flott             0.000000           24\n"
     ]
    }
   ],
   "source": [
    "# Calculate aggression rate per CB\n",
    "cb_aggression = results_df.groupby('cb_name').agg({\n",
    "    'decision_type': lambda x: (x == 'AGGRESSIVE').sum() / len(x),\n",
    "    'game_id': 'count'\n",
    "}).rename(columns={'decision_type': 'aggression_rate', 'game_id': 'total_plays'})\n",
    "\n",
    "# Filter to CBs with 20+ plays\n",
    "cb_aggression = cb_aggression[cb_aggression['total_plays'] >= 20]\n",
    "cb_aggression = cb_aggression.sort_values('aggression_rate', ascending=False)\n",
    "\n",
    "print(\"Most aggressive CBs (players with 20+ plays):\")\n",
    "print(cb_aggression.head(10))\n",
    "\n",
    "print(\"\\nMost conservative CBs:\")\n",
    "print(cb_aggression.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85685f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kyle Dugger vs Isaiah McKenzie (AGG: Overcommit (Beaten))\n",
      "    frame_id  separation  sep_change\n",
      "0          1    8.498435         NaN\n",
      "1          2    8.576788    0.078353\n",
      "2          3    8.673506    0.096717\n",
      "3          4    8.788822    0.115317\n",
      "4          5    8.917937    0.129115\n",
      "5          6    9.039386    0.121449\n",
      "6          7    9.168042    0.128656\n",
      "7          8    9.286980    0.118938\n",
      "8          9    9.404169    0.117189\n",
      "9         10    9.513622    0.109453\n",
      "10        11    9.614141    0.100519\n",
      "11        12    9.708785    0.094644\n",
      "12        13    9.814443    0.105659\n",
      "13        14    9.908628    0.094184\n",
      "14        15   10.003929    0.095302\n",
      "15        16   10.110020    0.106091\n",
      "\n",
      "Jordan Battle vs Devin Singletary (AGG: Undercut Fail (Complete))\n",
      "   frame_id  separation  sep_change\n",
      "0         1    8.918705         NaN\n",
      "1         2    8.497635   -0.421070\n",
      "2         3    8.060484   -0.437151\n",
      "3         4    7.619324   -0.441160\n",
      "4         5    7.174204   -0.445120\n",
      "5         6    6.748874   -0.425330\n",
      "6         7    6.290000   -0.458874\n",
      "7         8    5.851444   -0.438556\n",
      "\n",
      "Brandon Jones vs JuJu Smith-Schuster (AGG: Undercut Fail (Complete))\n",
      "    frame_id  separation  sep_change\n",
      "0          1    6.222387         NaN\n",
      "1          2    6.100836   -0.121551\n",
      "2          3    6.005239   -0.095597\n",
      "3          4    5.878818   -0.126421\n",
      "4          5    5.751947   -0.126870\n",
      "5          6    5.600571   -0.151376\n",
      "6          7    5.443942   -0.156630\n",
      "7          8    5.261036   -0.182906\n",
      "8          9    5.088693   -0.172343\n",
      "9         10    4.873110   -0.215583\n",
      "10        11    4.648441   -0.224669\n",
      "\n",
      "Jason Pinnock vs Byron Pringle (AGG: Undercut Fail (Complete))\n",
      "    frame_id  separation  sep_change\n",
      "0          1   15.747025         NaN\n",
      "1          2   15.199980   -0.547045\n",
      "2          3   14.593084   -0.606896\n",
      "3          4   13.934307   -0.658777\n",
      "4          5   13.247377   -0.686929\n",
      "5          6   12.520783   -0.726594\n",
      "6          7   11.764778   -0.756005\n",
      "7          8   11.002591   -0.762187\n",
      "8          9   10.242832   -0.759759\n",
      "9         10    9.459577   -0.783254\n",
      "10        11    8.680737   -0.778840\n",
      "11        12    7.915914   -0.764823\n",
      "\n",
      "Jordan Whitehead vs Jake Ferguson (AGG: Successful Jump (INC))\n",
      "    frame_id  separation  sep_change\n",
      "0          1    2.479516         NaN\n",
      "1          2    2.752817    0.273301\n",
      "2          3    3.023938    0.271121\n",
      "3          4    2.998966   -0.024971\n",
      "4          5    3.090760    0.091794\n",
      "5          6    3.136001    0.045240\n",
      "6          7    3.155202    0.019201\n",
      "7          8    3.148412   -0.006790\n",
      "8          9    3.153363    0.004951\n",
      "9         10    3.162436    0.009072\n",
      "10        11    3.178128    0.015693\n",
      "11        12    3.201281    0.023153\n",
      "12        13    3.220078    0.018797\n",
      "13        14    3.285392    0.065314\n",
      "14        15    3.313080    0.027688\n",
      "15        16    3.323883    0.010803\n"
     ]
    }
   ],
   "source": [
    "# For each aggressive play, when does separation start increasing?\n",
    "def analyze_break_timing(game_id, play_id, cb_id, wr_id):\n",
    "    \"\"\"Calculate frame-by-frame separation to find break point\"\"\"\n",
    "    \n",
    "    cb_data = output_df[\n",
    "        (output_df['game_id'] == game_id) & \n",
    "        (output_df['play_id'] == play_id) & \n",
    "        (output_df['nfl_id'] == cb_id)\n",
    "    ].sort_values('frame_id')\n",
    "    \n",
    "    wr_data = output_df[\n",
    "        (output_df['game_id'] == game_id) & \n",
    "        (output_df['play_id'] == play_id) & \n",
    "        (output_df['nfl_id'] == wr_id)\n",
    "    ].sort_values('frame_id')\n",
    "    \n",
    "    merged = pd.merge(cb_data, wr_data, on='frame_id', suffixes=('_cb', '_wr'))\n",
    "    merged['separation'] = np.sqrt(\n",
    "        (merged['x_cb'] - merged['x_wr'])**2 + \n",
    "        (merged['y_cb'] - merged['y_wr'])**2\n",
    "    )\n",
    "    \n",
    "    # When does separation start increasing?\n",
    "    merged['sep_change'] = merged['separation'].diff()\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Sample a few aggressive plays\n",
    "aggressive_sample = results_df[\n",
    "    results_df['decision_type'] == 'AGGRESSIVE'\n",
    "].sample(5)\n",
    "\n",
    "for idx, row in aggressive_sample.iterrows():\n",
    "    timing = analyze_break_timing(\n",
    "        row['game_id'], row['play_id'], \n",
    "        row['cb_id'], row['wr_id']\n",
    "    )\n",
    "    print(f\"\\n{row['cb_name']} vs {row['wr_name']} ({row['classification']})\")\n",
    "    print(timing[['frame_id', 'separation', 'sep_change']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a22e5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold = 25°:\n",
      "  Aggressive plays: 497 (13.3%)\n",
      "  Success rate: 35.6%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'route_of_targeted_receiver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Success rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(agg_test[agg_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_result\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIN\u001b[39m\u001b[38;5;124m'\u001b[39m])])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(agg_test)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Check route patterns\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m route_success \u001b[38;5;241m=\u001b[39m agg_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_of_targeted_receiver\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x[x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_result\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIN\u001b[39m\u001b[38;5;124m'\u001b[39m])]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     23\u001b[0m )\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Top routes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroute_success\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   8879\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1279\u001b[0m         obj,\n\u001b[1;32m   1280\u001b[0m         keys,\n\u001b[1;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'route_of_targeted_receiver'"
     ]
    }
   ],
   "source": [
    "# Try different direction_change thresholds\n",
    "thresholds_to_test = [25, 30, 35, 40, 45, 50]\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    # Reclassify with new threshold\n",
    "    results_df['is_agg_test'] = (\n",
    "        (results_df['direction_change_degrees'] > threshold) & \n",
    "        (results_df['separation_change'] > 0.5)\n",
    "    ) | (\n",
    "        (results_df['los_change_diff'] < -2.5) & \n",
    "        (results_df['separation_end'] > 4)\n",
    "    )\n",
    "    \n",
    "    agg_test = results_df[results_df['is_agg_test']]\n",
    "    \n",
    "    print(f\"\\nThreshold = {threshold}°:\")\n",
    "    print(f\"  Aggressive plays: {len(agg_test)} ({len(agg_test)/len(results_df)*100:.1f}%)\")\n",
    "    print(f\"  Success rate: {len(agg_test[agg_test['pass_result'].isin(['I','IN'])])/len(agg_test)*100:.1f}%\")\n",
    "    \n",
    "    # Check route patterns\n",
    "    route_success = agg_test.groupby('route_of_targeted_receiver').apply(\n",
    "        lambda x: len(x[x['pass_result'].isin(['I','IN'])]) / len(x) * 100\n",
    "    ).sort_values(ascending=False)\n",
    "    print(f\"  Top routes: {route_success.head(3).to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
